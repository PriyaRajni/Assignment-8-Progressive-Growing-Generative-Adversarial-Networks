{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85b60068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Reshape, Flatten, Add,\n",
    "    Conv2D, UpSampling2D, AveragePooling2D,\n",
    "    LeakyReLU\n",
    ")\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1870553",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/Users/priyarajni/Desktop/Pythoncode/MSAI-630-A02/celebA\"   \n",
    "RESULTS_DIR = \"./results\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "SEED = 42\n",
    "MAX_IMAGES = 10000          \n",
    "LATENT_DIM = 128             \n",
    "MAX_RESOLUTION = 64          \n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ade0425",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BLOCKS = int(np.log2(MAX_RESOLUTION)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9115a0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_NORMAL = [5] * N_BLOCKS\n",
    "EPOCHS_FADEIN = [5] * N_BLOCKS\n",
    "EPOCHS_FADEIN[0] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da8d1dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = [128, 128, 64, 32, 16][:N_BLOCKS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b2945c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21dcfecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_images(data_dir):\n",
    "    exts = (\".jpg\", \".jpeg\", \".png\", \".webp\")\n",
    "    files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.lower().endswith(exts)]\n",
    "    files.sort()\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc5f4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop_square(img):\n",
    "    # img: [H,W,3]\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    s = min(h, w)\n",
    "    y0 = (h - s) // 2\n",
    "    x0 = (w - s) // 2\n",
    "    return img[y0:y0+s, x0:x0+s, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a1a38fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_face_dataset_as_numpy(data_dir, max_images=MAX_IMAGES, target_res=MAX_RESOLUTION):\n",
    "    files = list_images(data_dir)\n",
    "    if len(files) == 0:\n",
    "        raise ValueError(f\"No images found in: {data_dir}\")\n",
    "    if len(files) > max_images:\n",
    "        files = random.sample(files, max_images)\n",
    "\n",
    "    X = []\n",
    "    for fp in tqdm(files, desc=\"Loading images\"):\n",
    "        raw = tf.io.read_file(fp)\n",
    "        img = tf.image.decode_image(raw, channels=3, expand_animations=False)\n",
    "        img = tf.cast(img, tf.float32).numpy()\n",
    "\n",
    "        img = center_crop_square(img)\n",
    "        img = tf.image.resize(img, (target_res, target_res), method=\"bilinear\").numpy()\n",
    "\n",
    "        # normalize to [-1, 1] like the tutorial expects\n",
    "        img = (img - 127.5) / 127.5\n",
    "        X.append(img)\n",
    "\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4de4f054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 10000/10000 [00:12<00:00, 816.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (10000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_face_dataset_as_numpy(DATA_DIR, MAX_IMAGES, MAX_RESOLUTION)\n",
    "print(\"Dataset shape:\", dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93f5530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNormalization(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        values = inputs**2.0\n",
    "        mean_values = backend.mean(values, axis=-1, keepdims=True)\n",
    "        mean_values += 1.0e-8\n",
    "        l2 = backend.sqrt(mean_values)\n",
    "        return inputs / l2\n",
    "\n",
    "class MinibatchStdev(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean = backend.mean(inputs, axis=0, keepdims=True)\n",
    "        squ_diffs = backend.square(inputs - mean)\n",
    "        mean_sq_diff = backend.mean(squ_diffs, axis=0, keepdims=True)\n",
    "        mean_sq_diff += 1e-8\n",
    "        stdev = backend.sqrt(mean_sq_diff)\n",
    "        mean_pix = backend.mean(stdev, keepdims=True)\n",
    "        shape = backend.shape(inputs)\n",
    "        output = backend.tile(mean_pix, (shape[0], shape[1], shape[2], 1))\n",
    "        return backend.concatenate([inputs, output], axis=-1)\n",
    "    \n",
    "class WeightedSum(Add):\n",
    "    def __init__(self, alpha=0.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.alpha = backend.variable(alpha, name=\"ws_alpha\")\n",
    "    def _merge_function(self, inputs):\n",
    "        assert len(inputs) == 2\n",
    "        return ((1.0 - self.alpha) * inputs[0]) + (self.alpha * inputs[1])\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return backend.mean(y_true * y_pred)\n",
    "\n",
    "def update_fadein(models, step, n_steps):\n",
    "    alpha = step / float(n_steps - 1) if n_steps > 1 else 1.0\n",
    "    for model in models:\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, WeightedSum):\n",
    "                backend.set_value(layer.alpha, alpha)\n",
    "\n",
    "def scale_dataset(images, new_shape_hw_c):\n",
    "    # new_shape_hw_c: (H,W,C)\n",
    "    new_h, new_w, _ = new_shape_hw_c\n",
    "    scaled = tf.image.resize(images, (new_h, new_w), method=\"bilinear\").numpy()\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40881154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_generator_block(old_model):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    block_end = old_model.layers[-2].output\n",
    "\n",
    "    up = UpSampling2D()(block_end)  # <-- upsampling choice (you will discuss this)\n",
    "    g = Conv2D(128, (3,3), padding=\"same\", kernel_initializer=init, kernel_constraint=const)(up)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(0.2)(g)\n",
    "    g = Conv2D(128, (3,3), padding=\"same\", kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(0.2)(g)\n",
    "\n",
    "    out_image = Conv2D(3, (1,1), padding=\"same\", kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    model1 = Model(old_model.input, out_image)\n",
    "\n",
    "    out_old = old_model.layers[-1]     # previous toRGB layer\n",
    "    out_image2 = out_old(up)           # old toRGB applied to upsampled features\n",
    "\n",
    "    merged = WeightedSum()([out_image2, out_image])\n",
    "    model2 = Model(old_model.input, merged)\n",
    "    return [model1, model2]\n",
    " \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "855b9d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim, n_blocks, in_dim=4):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    model_list = []\n",
    "\n",
    "    in_latent = Input(shape=(latent_dim,))\n",
    "    g = Dense(128 * in_dim * in_dim, kernel_initializer=init, kernel_constraint=const)(in_latent)\n",
    "    g = Reshape((in_dim, in_dim, 128))(g)\n",
    "\n",
    "    g = Conv2D(128, (3,3), padding=\"same\", kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(0.2)(g)\n",
    "    g = Conv2D(128, (3,3), padding=\"same\", kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(0.2)(g)\n",
    "\n",
    "    out_image = Conv2D(3, (1,1), padding=\"same\", kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    model = Model(in_latent, out_image)\n",
    "    model_list.append([model, model])\n",
    "\n",
    "    for _ in range(1, n_blocks):\n",
    "        models = add_generator_block(model_list[-1][0])\n",
    "        model_list.append(models)\n",
    "\n",
    "    return model_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f680f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_discriminator_block(old_model, n_input_layers=3):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    in_shape = list(old_model.input.shape)\n",
    "\n",
    "    input_shape = (int(in_shape[-2]*2), int(in_shape[-2]*2), int(in_shape[-1]))\n",
    "    in_image = Input(shape=input_shape)\n",
    "\n",
    "    d = Conv2D(128, (1,1), padding=\"same\", kernel_initializer=init, kernel_constraint=const)(in_image)\n",
    "    d = LeakyReLU(0.2)(d)\n",
    "\n",
    "    d = Conv2D(128, (3,3), padding=\"same\", kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(0.2)(d)\n",
    "    d = Conv2D(128, (3,3), padding=\"same\", kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(0.2)(d)\n",
    "    d = AveragePooling2D()(d)\n",
    "\n",
    "    block_new = d\n",
    "\n",
    "    for i in range(n_input_layers, len(old_model.layers)):\n",
    "        d = old_model.layers[i](d)\n",
    "    model1 = Model(in_image, d)\n",
    "    model1.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.001, beta_1=0.0, beta_2=0.99, epsilon=1e-8))\n",
    "    down = AveragePooling2D()(in_image)\n",
    "    block_old = old_model.layers[1](down)\n",
    "    block_old = old_model.layers[2](block_old)\n",
    "    d = WeightedSum()([block_old, block_new])\n",
    "    for i in range(n_input_layers, len(old_model.layers)):\n",
    "        d = old_model.layers[i](d)\n",
    "\n",
    "    model2 = Model(in_image, d)\n",
    "    model2.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.001, beta_1=0.0, beta_2=0.99, epsilon=1e-8))\n",
    "\n",
    "    return [model1, model2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33e7c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(n_blocks, input_shape=(4,4,3)):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    model_list = []\n",
    "\n",
    "    in_image = Input(shape=input_shape)\n",
    "    d = Conv2D(128, (1,1), padding=\"same\", kernel_initializer=init, kernel_constraint=const)(in_image)\n",
    "    d = LeakyReLU(0.2)(d)\n",
    "    d = MinibatchStdev()(d)\n",
    "    d = Conv2D(128, (3,3), padding=\"same\", kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(0.2)(d)\n",
    "    d = Conv2D(128, (4,4), padding=\"same\", kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(0.2)(d)\n",
    "    d = Flatten()(d)\n",
    "    out_class = Dense(1)(d)\n",
    "\n",
    "    model = Model(in_image, out_class)\n",
    "    model.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.001, beta_1=0.0, beta_2=0.99, epsilon=1e-8))\n",
    "    model_list.append([model, model])\n",
    "\n",
    "    for _ in range(1, n_blocks):\n",
    "        models = add_discriminator_block(model_list[-1][0])\n",
    "        model_list.append(models)\n",
    "\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36914379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_composite(discriminators, generators):\n",
    "    model_list = []\n",
    "    for i in range(len(discriminators)):\n",
    "        g_models, d_models = generators[i], discriminators[i]\n",
    "\n",
    "        d_models[0].trainable = False\n",
    "        model1 = Sequential([g_models[0], d_models[0]])\n",
    "        model1.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.001, beta_1=0.0, beta_2=0.99, epsilon=1e-8))\n",
    "\n",
    "        d_models[1].trainable = False\n",
    "        model2 = Sequential([g_models[1], d_models[1]])\n",
    "        model2.compile(loss=wasserstein_loss, optimizer=Adam(learning_rate=0.001, beta_1=0.0, beta_2=0.99, epsilon=1e-8))\n",
    "\n",
    "        model_list.append([model1, model2])\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af422e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    y = np.ones((n_samples, 1), dtype=np.float32)\n",
    "    return X, y\n",
    "\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = np.random.randn(latent_dim * n_samples).astype(np.float32)\n",
    "    return x_input.reshape(n_samples, latent_dim)\n",
    "\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = generator.predict(x_input, verbose=0)\n",
    "    y = -np.ones((n_samples, 1), dtype=np.float32)\n",
    "    return X, y\n",
    "\n",
    "def summarize_performance(status, g_model, latent_dim, n_samples=25):\n",
    "    gen_shape = g_model.output_shape\n",
    "    name = \"%03dx%03d-%s\" % (gen_shape[1], gen_shape[2], status)\n",
    "\n",
    "    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    X = (X - X.min()) / (X.max() - X.min() + 1e-8)\n",
    "    n = int(np.sqrt(n_samples))\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for i in range(n*n):\n",
    "        plt.subplot(n, n, i+1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(X[i])\n",
    "    out_path = os.path.join(RESULTS_DIR, f\"{name}.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # save generator\n",
    "    g_model.save(os.path.join(RESULTS_DIR, f\"{name}.keras\"))\n",
    "    print(\"Saved:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2ec9b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(g_model, d_model, gan_model, dataset, n_epochs, n_batch, fadein=False):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    half_batch = n_batch // 2\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        if fadein:\n",
    "            update_fadein([g_model, d_model, gan_model], step, n_steps)\n",
    "\n",
    "        X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "        X_fake, y_fake = generate_fake_samples(g_model, LATENT_DIM, half_batch)\n",
    "\n",
    "        d_loss1 = d_model.train_on_batch(X_real, y_real)\n",
    "        d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n",
    "\n",
    "        z_input = generate_latent_points(LATENT_DIM, n_batch)\n",
    "        y_gan = np.ones((n_batch, 1), dtype=np.float32)  # generator wants D to output \"real\" (positive)\n",
    "\n",
    "        g_loss = gan_model.train_on_batch(z_input, y_gan)\n",
    "\n",
    "        if (step+1) % max(1, (bat_per_epo//2)) == 0:\n",
    "            print(f\">{step+1}/{n_steps}, d1={d_loss1:.3f}, d2={d_loss2:.3f}, g={g_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b244118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_models, d_models, gan_models, dataset, latent_dim, e_norm, e_fadein, n_batch):\n",
    "    # stage 0 (4x4)\n",
    "    g_normal, d_normal, gan_normal = g_models[0][0], d_models[0][0], gan_models[0][0]\n",
    "    gen_shape = g_normal.output_shape\n",
    "    scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
    "    print(\"Scaled Data:\", scaled_data.shape)\n",
    "\n",
    "    train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[0], n_batch[0], fadein=False)\n",
    "    summarize_performance(\"tuned\", g_normal, latent_dim)\n",
    "\n",
    "    # progressive stages\n",
    "    for i in range(1, len(g_models)):\n",
    "        g_normal, g_fadein = g_models[i]\n",
    "        d_normal, d_fadein = d_models[i]\n",
    "        gan_normal, gan_fadein = gan_models[i]\n",
    "\n",
    "        gen_shape = g_normal.output_shape\n",
    "        scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
    "        print(\"Scaled Data:\", scaled_data.shape)\n",
    "\n",
    "        # fade-in training\n",
    "        if e_fadein[i] > 0:\n",
    "            train_epochs(g_fadein, d_fadein, gan_fadein, scaled_data, e_fadein[i], n_batch[i], fadein=True)\n",
    "            summarize_performance(\"faded\", g_fadein, latent_dim)\n",
    "        train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[i], n_batch[i], fadein=False)\n",
    "        summarize_performance(\"tuned\", g_normal, latent_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4733b803",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AveragePooling2D.__init__() missing 1 required positional argument: 'pool_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m g_models = define_generator(LATENT_DIM, N_BLOCKS)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m d_models = \u001b[43mdefine_discriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN_BLOCKS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m gan_models = define_composite(d_models, g_models)\n\u001b[32m      5\u001b[39m train(g_models, d_models, gan_models,\n\u001b[32m      6\u001b[39m       dataset=dataset,\n\u001b[32m      7\u001b[39m       latent_dim=LATENT_DIM,\n\u001b[32m      8\u001b[39m       e_norm=EPOCHS_NORMAL,\n\u001b[32m      9\u001b[39m       e_fadein=EPOCHS_FADEIN,\n\u001b[32m     10\u001b[39m       n_batch=BATCH_SIZES)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mdefine_discriminator\u001b[39m\u001b[34m(n_blocks, input_shape)\u001b[39m\n\u001b[32m     19\u001b[39m model_list.append([model, model])\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, n_blocks):\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     models = \u001b[43madd_discriminator_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     model_list.append(models)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_list\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36madd_discriminator_block\u001b[39m\u001b[34m(old_model, n_input_layers)\u001b[39m\n\u001b[32m     14\u001b[39m d = Conv2D(\u001b[32m128\u001b[39m, (\u001b[32m3\u001b[39m,\u001b[32m3\u001b[39m), padding=\u001b[33m\"\u001b[39m\u001b[33msame\u001b[39m\u001b[33m\"\u001b[39m, kernel_initializer=init, kernel_constraint=const)(d)\n\u001b[32m     15\u001b[39m d = LeakyReLU(\u001b[32m0.2\u001b[39m)(d)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m d = \u001b[43mAveragePooling2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m(d)\n\u001b[32m     18\u001b[39m block_new = d\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_input_layers, \u001b[38;5;28mlen\u001b[39m(old_model.layers)):\n",
      "\u001b[31mTypeError\u001b[39m: AveragePooling2D.__init__() missing 1 required positional argument: 'pool_size'"
     ]
    }
   ],
   "source": [
    "g_models = define_generator(LATENT_DIM, N_BLOCKS)\n",
    "d_models = define_discriminator(N_BLOCKS, input_shape=(4,4,3))\n",
    "gan_models = define_composite(d_models, g_models)\n",
    "\n",
    "train(g_models, d_models, gan_models,\n",
    "      dataset=dataset,\n",
    "      latent_dim=LATENT_DIM,\n",
    "      e_norm=EPOCHS_NORMAL,\n",
    "      e_fadein=EPOCHS_FADEIN,\n",
    "      n_batch=BATCH_SIZES)\n",
    "\n",
    "print(\"Done. Check ./results for output images and saved .keras models.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvMLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
